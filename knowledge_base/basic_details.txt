You are AkBot , a friendly AI assistant created by Anik Chand.
-Your main role is to share details ONLY about Anik Chand — his projects, skills, experiences, and portfolio.
-If asked something outside this scope (like politics, sports, or general knowledge), reply politely:
“I’m here to talk about Anik Chand and his work. Would you like to know about his projects, skills, or experiences?”
you can go beyong that scope ... but not too much. You can do simple maths calculations.
-Keep responses short, warm, and conversational. Add emojis occasionally 🙂.
-For technical topics, explain in a simple and clear way.
-For personal topics, respond empathetically.




The details of me (Anik Chand) are below:


📄 Knowledge Base: Anik Chand

### 👤 About Me

I am Anik Chand, passionate about AI/ML, deep learning, and building intelligent systems.
I love solving real-world problems using data-driven approaches, and I actively contribute to open-source and mentoring initiatives.

Anik chand address :
Birbhum, West Bengal, India

portfolio link : https://portfolio-fawn-beta-28.vercel.app
resume link : https://drive.google.com/file/d/1CdQwBAh4v6P90z_6Bm2dG1g8lLMJbpHh/view

Anik Chand's resume link : https://drive.google.com/file/d/1CdQwBAh4v6P90z_6Bm2dG1g8lLMJbpHh/view

gmail : anikchand461@gmail.com
linkedin : https://www.linkedin.com/in/anik-chand-3b14b12b6/
github : https://github.com/anikchand461
kaggle : https://www.kaggle.com/anikchand
codolio account link : https://codolio.com/profile/anikchand461
mobile : +91 9153772355



## projects made by Anik Chand

### 💬 AkBot

project link live link : https://akbot-mxe4.onrender.com

An AI-powered personalized chatbot built using RAG + Gemini API, integrated with FastAPI backend, ChromaDB for vector storage, and a responsive JS frontend. Deployed seamlessly on Render.

🚀 Features

🧠 Retrieval-Augmented Generation (RAG) for contextual answers from personal/project data
⚡ FastAPI Backend for handling chatbot requests
📂 ChromaDB as vector database for efficient embeddings & retrieval
🤖 Gemini API integration for LLM responses
🌐 Frontend with HTML/CSS/JS for chat interface
☁️ Deployed on Render with environment-based API key management
🛠 Tech Stack

Backend: FastAPI, LangChain
Vector DB: ChromaDB
LLM API: Gemini API
Frontend: HTML, CSS, JavaScript
Deployment: Render
⚙️ Setup & Installation

Clone the repo

git clone https://github.com/anikchand461/AkBot.git
cd ai-chatbot
Create virtual environment & install dependencies

python -m venv venv
source venv/bin/activate   # On Windows: venv\Scripts\activate
pip install -r requirements.txt
Set up environment variables
Create a .env file in the project root:

GEMINI_API_KEY=your_api_key_here
Run the backend

uvicorn app.main:app --reload
Open the frontend
Open index.html in your browser, or serve via any static hosting.

📦 Deployment on Render

Push your repo to GitHub.
Create a Render Web Service → select FastAPI backend.
Add GEMINI_API_KEY under Environment Variables in Render Dashboard.
Deploy 🚀


### 🐦 tierlesstweet

Generate high-quality, engaging Twitter (X) posts and matching AI-generated images based on your content's tone — whether it's for casual users, blue-tick professionals, or golden-tick brands.

🌐 Live Demo

🚀 Features

✍️ AI-Generated Tweets Uses Gemini 2.5 Flash to craft single-post tweets tailored to different Twitter tiers:

No Tick: Short, punchy tweets under 280 characters.
Blue Tick: Polished posts under 2500 characters.
Golden Tick: In-depth, authoritative content without character limits.
🎨 AI-Generated Images Uses Nebius AI Studio (Flux Schnell) to generate a unique image that matches the tweet content.

🔍 Clean Output Tweets are stripped of markdown formatting to ensure clean, platform-ready output.

📁 Auto-Save Images are saved and served from the /static/generated_images directory.

🛠️ Tech Stack

Backend: Python, Flask
LLM: Google Generative AI (Gemini 2.5 Flash)
Image Generator: Nebius AI Studio (Flux Schnell)
Deployment: Render
📸 Preview

Example Screenshot

Demo of tweet and image generation interface.
📂 Project Structure

tierlesstweet/
│
├── static/
│   └── generated_images/
├── templates/
│   └── index.html
├── .env
├── app.py
└── README.md
🔧 Setup Instructions

Clone the Repository

git clone https://github.com/yourusername/tierlesstweet.git
cd tierlesstweet
Create and Activate a Virtual Environment

python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
Install Dependencies

pip install -r requirements.txt
Set Up Environment Variables Create a .env file and add your API keys:

GENAI_API_KEY=your_google_genai_key
NEBIUS_API_KEY=your_nebius_api_key
Run the App

python app.py
Open in Browser Navigate to http://127.0.0.1:5000 in your browser.

🧠 How It Works

User inputs keywords and selects a tweet type (No Tick, Blue Tick, Golden Tick).
A prompt is built and passed to the Gemini model.
The resulting tweet is cleaned and passed as a prompt to the Nebius image model.
The tweet and its matching AI-generated image are displayed together.
✨ Future Improvements

User authentication and history tracking
Option to download tweet + image as a bundle
Twitter API integration for direct posting
Dark mode UI and mobile responsiveness
📜 License

This project is licensed under the MIT License.

👨‍💼 Author

Made with ❤️ by Abhiraj Adhikary and Anik Chand






### 🧠 Sentiment Analysis

This project demonstrates a stacking ensemble for a classification task on a high-dimensional, sparse dataset. It leverages several classical machine learning algorithms and builds a deep stacking pipeline with performance tuning and cross-validation to achieve high accuracy.

live link : https://sentimentt-analysis.streamlit.app

📊 Dataset

Shape: (50000, 73392)
Type: Sparse matrix (99.87% sparse)
Features: Preprocessed vectorized inputs (likely from text data such as TF-IDF or bag-of-words)
Labels: Multi-class or binary classification
🛡️ Stacking Architecture

Layer 0 (Base Models):
    ✔️ SGDClassifier
    ✔️ LogisticRegression
    ✔️ LinearSVC
    ✔️ MultinomialNB

↓ Outputs

Layer 1 (Meta Model):
    ✔️ LogisticRegression
✅ Final Accuracy Results

Model	Accuracy (%)
MultinomialNB	85.41
BernoulliNB	85.27
LogisticRegression	88.64
LinearSVC	88.54
SGDClassifier	88.65
RidgeClassifier	86.09
PassiveAggressive	81.02
1-Layer Stack	89.15 ✅
Deep Stack (2 layers)	89.09
✅ Best performance achieved using 1-layer stacking with Logistic Regression as the meta-model.
🧪 Techniques Used

train_test_split from sklearn.model_selection

Grid Search (GridSearchCV) for hyperparameter tuning:

C for LogisticRegression, LinearSVC
alpha for MultinomialNB, SGDClassifier
StackingClassifier for layered architecture

accuracy_score for evaluation

mode() for hard voting in final layer

🧠 Requirements

Install necessary packages:

pip install numpy scikit-learn scipy
🧠 Learning Highlights

Using classical ML models in a stacked architecture
Understanding how and when additional layers in stacking help (or don’t)
Measuring accuracy improvements layer-by-layer using validation and voting
📊 Model Progression & Insights

This section outlines the iterative improvements made during model experimentation:

🔹 Baseline Models (Naive Bayes Family)

Model	Accuracy (%)
GaussianNB	82.00
BernoulliNB	83.00
MultinomialNB	83.50
🔹 After Hyperparameter Tuning (Grid Search)

Model	Tuned Accuracy (%)
MultinomialNB (alpha)	85.40
🔹 Ensemble of Classical ML Models

Tried:

LogisticRegression
SGDClassifier
RidgeClassifier
PassiveAggressiveClassifier
LinearSVC
Among them, 4 models performed best, achieving around 87% accuracy.

🔹 Grid Search on Top 4 Models

After tuning C, alpha, penalty, loss, the best accuracy improved to 88.6%.

🔹 Stacking

Performed model stacking with:

Base Models: MultinomialNB, SGD, LogisticRegression, LinearSVC
Meta Model: LogisticRegression (solver='lbfgs')
Cross-Validation: 5-fold
🌟 Final Accuracy: 89.12% 🌟 Cross-Validation Score: 89.15%

🔹 Multi-layer Stacking Attempt

Tried adding a second stacking layer with Ridge & SGD followed by hard voting.

Result: Accuracy dropped to 89.09%
Conclusion: Layer 1 was already optimal. Extra depth didn’t help.




### 🧠 Personality Predictor

A Streamlit web app that predicts whether a person is an introvert or extrovert based on behavioral traits using a Random Forest Classifier.

🔗 Live Demo

👉 Click to Try the App

📌 Features

Takes in 4 simple inputs:

Social event attendance
Frequency of going outside
Social media post frequency
Friends circle size
Predicts personality type: Introvert 🪫 or Extrovert 🎉

Built with:

Python 🐍
Scikit-learn
Streamlit
Joblib
🧪 Dataset Info

Source: Kaggle Dataset

2900 rows × 8 columns

Preprocessing steps:

Converted categorical variables to binary (Yes/No → 1/0)
Selected features with positive correlation to target
Imputed missing values using SimpleImputer
Used Random Forest for classification
⚙️ How to Run Locally

1. Clone the Repository

git clone https://github.com/your-username/personality-predictor.git
cd personality-predictor
2. Install Requirements

pip install -r requirements.txt
3. Run Streamlit App

streamlit run app.py
📁 File Structure

├── app.py                # Main Streamlit app
├── personality_model.pkl # Trained Random Forest model
├── requirements.txt      # Python dependencies
└── README.md             # Project documentation
📊 Model Performance

✅ Accuracy: 90.3%
📈 R² Score: 0.62
✔️ Trained using RandomForestClassifier from Scikit-learn
📄 License

This project is licensed under the MIT License.

🙇‍♂️ Author

Developed by Anik Chand

🔗 LinkedIn | GitHub





### Quizly - AI-Powered Quiz Generation Application

Quizly is a state-of-the-art quiz generation application that utilizes the Google Gemini Generative AI API to create sophisticated, context-aware multiple-choice questions based on user-specified topics. Developed with a robust FastAPI backend and a clean, responsive HTML/CSS/JavaScript frontend, Quizly delivers a seamless user experience for learners and educators alike.

Features • AI-driven generation of dynamic, multiple-choice questions across a wide range of topics • Provides instant feedback and assessment for questions • Integrates with the Google Gemini API for advanced, context-rich question generation • User-friendly, clean, and minimalist interface

Tech Stack

Layer Technology Backend FastAPI Frontend HTML, CSS, JavaScript AI Model Google Gemini via API

Installation 1. Clone the Repository:

git clone https://github.com/your-username/Quizly.git cd Quizly

2.	Install Dependencies:
pip install -r requirements.txt

3.	Setup Environment Variables:
Create a .env file with your Gemini API key:

GENAI_API_KEY=your_google_gemini_api_key

4.	Run the Application Locally:
uvicorn main:app --reload

Deployment • Render: Set the start command as unicorn main:app --reload. • Railway: Configure the app and obtain the deployment URL from the Railway dashboard.

Usage 1. Open the app in a browser. 2. Enter desired topics (comma-separated). 3. Choose the number of questions. 4. Click “Generate Quiz” to begin.

Contributing

We welcome contributions. To propose changes or enhancements, open an issue for discussion first. All PRs must adhere to project coding and documentation standards.

Authors 

Anik Chand and Abhiraj Adhikary





### 🚨 Report Connect
AI-Powered Crime Hotspot Prediction & Reporting Platform

📌 Overview

This project is an AI-driven platform that allows users to anonymously report harassment cases while utilizing Machine Learning to predict potential crime hotspots. By combining crowdsourced data and AI-based analysis, it helps authorities and the public identify high-risk areas and take preventive measures.

🔥 Key Features

✅ 1. Anonymous & Secure Reporting

Users can report harassment cases without revealing their identity.
The reports include location, type of harassment, and description.
🌍 2. Real-Time Crime Mapping

A dynamic map displays reported harassment cases as red blurry markers.
More reports = Higher intensity, helping visualize crime-prone areas.
🤖 3. AI-Powered Hotspot Prediction

Uses Kernel Density Estimation (KDE) to predict the next potential crime hotspot.
The predicted hotspot is marked in green, with intensity decreasing from the most severe to least severe.
📈 4. Data-Driven Insights

A curved graph dynamically updates to show crime trends across different locations.
The system highlights the area with the most reports in real-time.
🔍 5. Crowdsourced Data Collection

Community-driven data collection improves predictive accuracy.
Allows law enforcement and citizens to stay informed about crime patterns.
⚡ 6. Scalability & Future Expansion

Designed to handle large-scale data entries.
Initially, a CSV dataset with 10,000 reports will populate the database for AI model training.
After reaching this milestone, reports will be manually submitted by users.
🛠 Tech Stack

Backend 🖥️

Django (Python) for server-side processing.
SQLite3 for managing reports and predictions.
Frontend 🐥

HTML, JavaScript, Bulma CSS for an intuitive user experience.
Leaflet.js & OpenStreetMap API for map visualization.
Machine Learning & AI 🤖

Kernel Density Estimation (KDE) for hotspot prediction.
Pandas & NumPy for data processing.
🔄 How It Works

1️⃣ Report Submission

Users enter location, type of harassment, and description.
The system automatically fetches latitude & longitude based on the location name.
The report is stored securely in the database.
2️⃣ Real-Time Visualization

A map dynamically updates to reflect new reports.
Crime hotspots are predicted using AI, ensuring proactive safety measures.
3️⃣ Prediction Mechanism

The AI model analyzes historical crime data.
KDE determines the most likely future crime locations.
The top 20 hotspots are displayed with decreasing intensity (green border with blurred green inside).
4️⃣ Prediction Mechanism

Community commenting feature to discuss about the crimes.
📂 Setting Up the Project

🔧 1. Clone the Repository

    git clone https://github.com/yourusername/Report-Connect.git
    cd Report-Connect
📦 2. Install Dependencies

    pip install -r requirements.txt
🔥 3. Run Migrations & Start Server

    python manage.py migrate
    python manage.py runserver
🚀 Future Enhancements

Advanced AI Models: Improve prediction accuracy with Deep Learning.
User Alerts: Send notifications when users are in high-risk zones.
Integration with Law Enforcement: Provide verified data to help authorities take action.
Multilingual Support: Expand accessibility to a wider audience.
🏆 Impact & Goals

Empower communities to report incidents without fear.
Assist law enforcement in focusing efforts on high-risk areas.
Utilize AI & Big Data for proactive crime prevention.
🫂 Together, we can make cities safer! 🔥

Authors -
Anik Chand, Abhiraj Adhikary, Anirban Chakraborty, Ayan Roy






### 💼 SalaryAi

SalaryAi is an AI-powered salary prediction web application built using FastAPI, Machine Learning, HTML, CSS, and JavaScript. It enables users to input professional details such as age, gender, education level, job title, and years of experience — and instantly get a predicted salary based on trained data.

⚠️ Note: This application is based on salary data from the United States. Predictions are aligned with typical U.S. salary ranges.
🚀 Features

🧠 Machine learning-powered salary predictions
🌐 Fast and lightweight API built with FastAPI
🎨 Responsive and user-friendly frontend interface
⬇️ Dynamic dropdowns populated directly from training dataset values
📦 Model and preprocessing pipeline stored using joblib
💠 Tech Stack

Category	Tools Used
Backend	Python, FastAPI
Frontend	HTML, CSS, JavaScript
Machine Learning	Pandas, Scikit-learn, Joblib
API Testing	FastAPI Docs (Swagger UI)
Deployment	Uvicorn (Locally) / Render
📊 Dataset Fields

Age (Float)
Gender (Dropdown: e.g., Male, Female, Other)
Education Level (Dropdown: e.g., Bachelor's, Master's, PhD)
Job Title (Dropdown: 190+ options from dataset)
Years of Experience (Float)
🖼️ Screenshot

SalaryAi Screenshot

🔧 How to Run Locally

1. Clone the Repository

git clone https://github.com/yourusername/SalaryAi.git
cd SalaryAi
2. Install Dependencies

pip install -r requirements.txt
3. Run the App

uvicorn main:app --reload
4. Access the Interface

Visit the frontend page at: http://localhost:8000
Or use the Swagger API at: http://localhost:8000/docs
📂 Project Structure

SalaryAi/
├── main.py                # FastAPI backend
├── predict_salary.pkl     # Trained ML pipeline      
├── static/
│   ├── index.html         # CSS styling, JavaScript logic
├── requirements.txt       # Python dependencies
└── README.md              # Project documentation
📌 Future Improvements

Add more countries and currencies
Authentication for user-specific history
Visualize trends with graphs (experience vs salary, etc.)
Host the model API on cloud
🧑‍💻 Author

Anik Chand LinkedIn • GitHub





### BillVault 📜💰

BillVault is a Django-powered web application for managing and tracking bills securely and efficiently. It allows users to register, log in, and perform tasks like creating, viewing, and managing their bills.

🔗 Live Site: https://billvault.pythonanywhere.com/accounts/login/

✨ Features

👤 User registration and authentication

🔐 Secure login/logout functionality

🧾 Create, view, update, and delete bills

🗂 Categorize and filter bills

📱 Responsive and user-friendly UI

🛠 Admin dashboard for managing data

⚙ Tech Stack

Backend: Django (🐍 Python)

Frontend: HTML, CSS, JavaScript (with Django Templates)

Database: SQLite 🗃 (default, configurable)

Hosting: PythonAnywhere ☁

🚀 Getting Started

✅ Prerequisites

Make sure you have the following installed:

🐍 Python 3.x

📦 pip

🌱 virtualenv (optional but recommended)

⚙ Installation

git clone https://github.com/your-username/billvault.git cd billvault python -m venv env source env/bin/activate # For Windows: env\Scripts\activate pip install -r requirements.txt python manage.py migrate python manage.py runserver

➡ Visit: http://127.0.0.1:8000/accounts/login/ to access the login page.

🧑‍💻 Usage

✍ Register a new account or log in

📋 Create and manage bills from your dashboard

🔎 Use filters to sort or find specific bills

🛡 Admins can manage users and system-wide data from the admin panel

📁 Folder Structure

billvault/ ├── accounts/ # 🔐 Custom user authentication ├── bills/ # 🧾 App for bill CRUD operations ├── static/ # 🎨 CSS, JS, images ├── templates/ # 🖼 HTML templates ├── manage.py ├── db.sqlite3 └── requirements.txt


Authors

Anik Chand , Abhiraj Adhikary, Ayan Roy, Anchal Sharma






### GitCollabIn

GitCollabIn is a web application designed to connect developers, foster collaboration, and streamline open-source project management. Integrated with GitHub, it allows users to share and contribute to projects while matching their skills with relevant opportunities.

Key Features

🔍 Skill-based project matching
🤝 Contributor request handling
🔐 GitHub OAuth login
🧭 Project listing and discovery
🧑‍💻 Custom user profiles
Built with Django, Bulma CSS, and JavaScript, and deployed via Render, it offers a scalable, modern, and developer-friendly experience.

How to List Your Project 🚀

🔐 Log In using your GitHub account.
➕ Click “Create Project” on the homepage/dashboard.
📝 Fill out the form:
🔗 GitHub repository URL (must match your username)
📄 Requirements description
👥 Number of contributors needed
💡 Desired skills
☕ Optional: Buy Me a Coffee, Patreon, or PayPal support
✅ Submit the project.
📌 Your project appears in the global list after validation.
How Collaborators Join Projects 👨‍💻👩‍💻

🔎 Browse the homepage for interesting projects.
📘 Click on a project to view details.
✉️ Submit a contributor request (visible if allowed).
🧾 Project owner reviews and accepts/rejects your request.
✅ Once accepted, you begin collaboration.
How Everyone Can View Projects 🌐

🏠 Visit the home page (/) to see all public projects.
📋 Projects include descriptions, skills needed, and contributor slots.
⚡ Cached GitHub data (README, forks) enhances performance.
🔍 Search & filter (planned) to help users find matching projects easily.
How to Get Your Matching Projects 🧠

🔐 Log in and update your skills in your profile.
✅ A “Matched Projects” section appears on the home page.
⚙️ Uses a skill-matching algorithm.
⏱️ Matching results are cached for 1 hour for better speed.
Automating Collaborator Requests 🤖

⏳ Requests are auto-stored as “pending”.
🔔 Project owners receive a notification.
🧾 Owner manually accepts or rejects requests.
📈 Future: Auto-accept based on skill/reputation using Celery tasks/signals.
Add Your GitHub Classic Token 🔑

🔐 Log in and go to Edit Profile.
📋 Paste your GitHub Classic Token (40 characters).
🛡️ Token is masked for security.
🚀 Used for enhanced API access (e.g., forks, issues).
How to Clone This Repository 💻

# Clone the repo
git clone https://github.com/anikchand461/GitCollabIn.git

# Navigate into the repo
cd GitCollabIn

# Create a virtual environment
python -m venv venv

# Activate it
# On Windows
venv\Scripts\activate
# On Mac/Linux
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure environment variables (if needed)

# Run migrations
python manage.py migrate

# Start the server
python manage.py runserver


---

Live Link 🔗

https://gitcollabin.onrender.com


---

Tech Stack 🛠️

Django: Backend framework for APIs and database interaction

Bulma CSS: Modern responsive CSS framework

JavaScript: Frontend interactivity

GitHub OAuth: Secure login and repository integration

Render: Hosting and deployment

---

Contribution ❤️

Contributions are welcome!
🧪 Clone the repo,
🛠️ Explore the features,
✨ Help build the future of open-source collaboration!

Authors

Anik Chand, Anchal Sharma, Abhiraj Adhikary







### 🌍 EcoFix - Your Environmental Guardian 🌿

EcoFix Banner

Welcome to EcoFix – a comprehensive platform dedicated to promoting environmental awareness and sustainability! 🚀 Whether you're passionate about reducing your carbon footprint or tracking environmental observations, EcoFix has you covered.

📦 Features

✨ Submit Environmental Observations
📸 Report environmental issues by submitting observations with photos and descriptions.

✨ Track Your Carbon Footprint
🚗🌱 Calculate your carbon emissions based on your transportation, diet, and energy usage.

✨ Real-Time Data Visualization
📊 Analyze your environmental impact with easy-to-understand charts and reports.

✨ User-Friendly Interface
💻 Intuitive design with responsive layouts for a seamless experience on all devices.

🚀 Technologies Used

Python 🐍
Django 🌐
HTML5 & CSS3 🎨
JavaScript ✨
Bulma CSS Framework 🛠️
SQLite 🗄️
🛠️ Installation & Setup Guide

Follow these steps to get EcoFix up and running on your local machine! 🖥️💡

### 1. Clone the Repository


git clone https://github.com/abhirajadhikary06/EcoFix.git
cd EcoFix

### 2. Set Up the Virtual Environment

python -m venv env
source env/bin/activate  # For Linux/Mac
# OR
env\\Scripts\\activate  # For Windows

### 3. Install Dependencies

pip install -r requirements.txt

### 4. Run Migrations

python manage.py makemigrations
python manage.py migrate

### 5. Start the Server 🚀

python manage.py runserver

Now, open your browser and go to http://127.0.0.1:8000 to explore EcoFix! 🌿
🖼️ Screenshots

🌍 Home Page

📸 Submit Observation

📊 Track Carbon Footprint

🤝 Contributing

We welcome contributions! 👐 Follow these simple steps: 1. Fork the repository 🍴 2. Create a new branch for your feature (git checkout -b feature-name) 🌱 3. Commit your changes (git commit -m 'Add some feature') 💾 4. Push to the branch (git push origin feature-name) 🚀 5. Open a Pull Request 📬

📜 License

This project is licensed under the MIT License.

Authors

Anik Chand, Abhiraj Adhikary, Anirban Chakraborty, Ayan Roy






### Global Disaster Network

Overview

The Global Disaster Network (GAN) is a comprehensive disaster management platform designed to empower communities, authorities, and individuals by providing real-time tools and resources to predict, monitor, and respond to natural disasters and calamities. Built with a focus on connectivity, accessibility, and transparency, GAN aims to reduce the impact of disasters through proactive measures, community engagement, and advanced technology.

This project leverages modern web technologies, AI-driven predictions, and real-time data to create a robust system for disaster preparedness and response. Below is a detailed breakdown of the features, setup instructions, and API documentation for developers.

Features

1. Prediction Map

The Prediction Map is a core feature of GAN, utilizing AI and machine learning to forecast potential natural disasters such as floods, wildfires, hurricanes, and earthquakes. Key aspects include:

Disaster Prediction: The map integrates historical data, weather patterns, and environmental factors to predict the likelihood of disasters in specific regions. For example, it can forecast flood risks based on rainfall data or wildfire risks based on temperature and humidity.
Nearest Hospital Locator: In the event of a predicted or ongoing disaster, the map highlights the nearest hospitals or shelters where users can seek refuge. It uses geolocation to provide real-time directions and estimated travel times.
Visual Representation: The map is interactive, displaying color-coded risk zones (e.g., red for high risk, yellow for moderate risk) and overlays for hospital locations.
2. Previous Disasters

This feature provides a historical database of past natural disasters, allowing users to learn from historical events and prepare for future ones.

Searchable Database: Users can search for disasters by location, date, or type (e.g., earthquake, tsunami).
Detailed Reports: Each entry includes details such as the disaster’s impact (casualties, economic loss), response efforts, and lessons learned.
Educational Resource: Helps communities understand recurring disaster patterns in their area, fostering better preparedness.
3. Latest News Related to Disasters

Stay informed with real-time news updates on ongoing and recent disasters worldwide.

News Aggregation: GAN pulls in the latest disaster-related news from trusted sources, ensuring users have access to up-to-date information.
Localized News: Users can filter news by region to focus on disasters affecting their area.
Alerts: Push notifications for breaking news about disasters in the user’s vicinity.
4. Community Connectivity

The Community Connectivity feature fosters collaboration among citizens during and after disasters, enabling them to support each other.

Disaster Reporting: Users can report disasters directly from their location, including details such as the type of disaster, severity, and current situation. Reports include geolocation data for precise mapping.
Communication Platform: Other users can view these reports, comment, and offer assistance or advice. For example, a user reporting a flood can receive messages from others offering shelter or supplies.
Community Forum: A dedicated space for users to discuss disaster preparedness, share experiences, and build local support networks.
5. Authority Login

A separate login portal for disaster management authorities provides a centralized dashboard to monitor and respond to disasters.

Disaster Monitoring: Authorities can view all reported disasters on a single map, with filters for type, severity, and location.
Real-Time Updates: Receive live updates from user reports and prediction models to prioritize response efforts.
Coordination Tools: Send alerts to citizens, coordinate with hospitals, and manage resources efficiently.
6. Chatbot for Natural Disasters and Calamities

An AI-powered chatbot provides instant support and information related to natural disasters.

Disaster Information: Users can ask questions like “What should I do during an earthquake?” or “How do I prepare for a hurricane?” The chatbot provides actionable advice based on best practices.
Real-Time Assistance: During a disaster, the chatbot can guide users to the nearest shelter or hospital and provide safety tips.
Multilingual Support: Available in multiple languages to ensure accessibility for diverse communities.
7. API Documentation

GAN provides a public API for developers to access previous disaster data, enabling integration with other applications.

Endpoint: GET /disasters/
Description: Fetch a list of previous disasters.
Parameters:
location (optional): Filter by location (e.g., "California").
type (optional): Filter by disaster type (e.g., "earthquake").
date_from (optional): Filter by start date (e.g., "2023-01-01").
date_to (optional): Filter by end date (e.g., "2023-12-31").
Response:
[
      {
    "year": 2020,
    "disaster_type": "Flood",
    "country": "India",
    "region": "Kerala",
    "location": "Alappuzha",
},
  ...
]
Authentication: Requires an API key, which can be obtained by registering on the GAN developer portal.
Rate Limit: 1000 requests per hour per API key.
8. Disaster Management Educational Videos

This feature provides users with access to curated educational videos on disaster management, helping them prepare for various types of natural disasters.

Disaster Type Selection: Users can select a specific disaster type (e.g., earthquake, flood, wildfire) to view relevant educational content.
YouTube Integration: The platform integrates with YouTube to display disaster management videos from trusted sources.
Interactive Learning: Videos include actionable tips, safety measures, and preparation guidelines to help users effectively respond to disasters.
Localized Content: Where available, videos tailored to specific regions or languages are prioritized to ensure relevance and accessibility.
Continuous Updates: The video library is regularly updated to include the latest and most accurate information on disaster management.
Installation

Prerequisites

Python 13.1
Django
A modern web browser (Chrome, Firefox, Edge)
API keys for map services (e.g., Google Maps API) and news aggregation (e.g., NewsAPI)
Setup Instructions

Clone the Repository:

git clone https://github.com/global-alert-network/gan.git
cd floodless
Install Dependencies:

pip install django
Configure Environment Variables: Create a .env file in the root directory and add the following:

GOOGLE_MAPS_API_KEY=your_google_maps_api_key
NEWS_API_KEY=your_news_api_key
DATABASE_URL=your_database_url
API_KEY=your_gan_api_key
Run the Application:

python manage.py runserver
The app will be available at http://localhost:8000.

Usage

Access the Platform:

Open your browser and navigate to http://localhost:8000 (or the deployed URL if hosted).
Register as a user to access community features, or log in as an authority using the separate login portal.
Explore Features:

Use the Prediction Map to view disaster forecasts and locate nearby hospitals.
Check the Previous Disasters section to learn about historical events.
Stay updated with the Latest News section.
Engage with the Community Connectivity feature to report disasters or communicate with others.
Authorities can log in to monitor and manage disaster responses.
Interact with the Chatbot for disaster-related guidance.
Developers can use the API to fetch disaster data for their applications.
Technologies Used

Frontend: HTML, Bulma CSS
Backend: Django
Database: PostgreSQL (for storing disaster data, user reports, etc.)
APIs:
Google Maps API (for Prediction Map and hospital locator)
NewsAPI (for latest news)
OpenWeather (for weather updates)
AI/ML: TensorFlow.js (for disaster prediction models)
Chatbot: Dialogflow (for natural language processing)
Styling: Bulma CSS
Contributing

We welcome contributions to the Global Disaster Network! To contribute:

Fork the repository.
Create a new branch (git checkout -b feature/your-feature).
Make your changes and commit them (git commit -m "Add your feature").
Push to your branch (git push origin feature/your-feature).
Open a pull request with a detailed description of your changes.
Please ensure your code follows our coding standards and includes tests where applicable.

License

This project is licensed under the MIT License.

Acknowledgments

Inspired by global disaster management initiatives like the United Nations Office for Disaster Risk Reduction (UNDRR).
Thanks to the open-source community for providing tools and libraries that made this project possible.
Special thanks to contributors who helped shape the vision of GAN.
The Global Disaster Network is committed to making the world a safer place by empowering communities with the tools they need to face natural disasters. Join us in building a more resilient future! 🌍


Authors

Anik Chand, Abhiraj Adhikary, Ayan Roy, Bholanath Dey








### Secure Line

Same as the project "Report Connect"








### EcoMate

same as project "EcoFix"









### 








